# LLM Flow Integration Test

Comprehensive test script that validates the entire LLM pipeline from hand selection to final analysis generation.

## Quick Start

```bash
# Run the full LLM flow test
npm run test:llm

# Or run directly
node scripts/test-llm-flow.js
```

## What It Tests

### Phase 1: Hand Selection & Context
- Finds a random hand that saw the river
- Displays hand metadata (cards, board, stacks, pot type)
- Generates snapshots using the existing pipeline

### Phase 2: Solver Integration
- Enriches snapshots with solver data using `Solves.prepareSnapshots()`
- Runs vector search for each snapshot
- Builds complete solver blocks with ranges, EV, recommendations
- Analyzes match rates and similarity scores

### Phase 3: LLM Processing
- Trims solver data using `SolverBlockTrimmer` for token efficiency
- Builds structured prompts using `LLMPromptBuilder` with UI tags
- Estimates token usage and API costs
- Calls `SolverLLMService.analyzeHand()` with full benchmarking
- Validates response structure and content

### Phase 4: Results & Performance
- Displays complete analysis with street comments and UI tags
- Shows identified mistakes with EV loss calculations
- Provides detailed performance metrics for each phase
- Reports token usage, costs, and provider statistics

## Sample Output

```
üöÄ Starting LLM Flow Integration Test
=================================================================================

üìã PHASE 1: Hand Selection & Context
--------------------------------------------------
Hand Context:
‚Ä¢ Hand ID: 109196
‚Ä¢ Hero Cards: 6d6c (UTG+1)
‚Ä¢ Board: 8d9sKh9c2h
‚Ä¢ Effective Stack: 23.9BB
‚Ä¢ Pot Type: SRP
‚Ä¢ Game Type: tournament
‚Ä¢ Saw Streets: Flop(‚úì) Turn(‚úì) River(‚úì)

‚Ä¢ Hand Selection         : 23ms
‚Ä¢ Snapshot Generation    : 15ms
‚Ä¢ Snapshots Created      : 4

‚ö° PHASE 2: Solver Integration
--------------------------------------------------
‚Ä¢ Solver Enrichment      : 2814ms
‚Ä¢ Enriched Snapshots     : 4
‚Ä¢ Solver Matches         : 3/4 (75%)
‚Ä¢ Average Similarity     : 0.847

Solver Insights:
‚Ä¢ Snapshot 1 (FLOP): Bet 4.5BB | EV: 12.34 | Sim: 89.2%
‚Ä¢ Snapshot 2 (TURN): Check | EV: 8.91 | Sim: 76.5%
‚Ä¢ Snapshot 3 (RIVER): Fold | EV: -2.15 | Sim: 92.1%
‚Ä¢ Snapshot 4 (RIVER): No solver data

ü§ñ PHASE 3: LLM Processing
--------------------------------------------------
‚Ä¢ Estimated Tokens       : 1156
‚Ä¢ Estimated Cost         : $0.0174
‚Ä¢ Provider               : openai
‚Ä¢ Complexity Score       : 6
‚Ä¢ LLM Processing         : 1389ms
‚Ä¢ Actual Tokens          : 1143
‚Ä¢ Actual Cost            : $0.0171

üìä PHASE 4: Results & Analysis
--------------------------------------------------
LLM Analysis Results:
‚Ä¢ Headline: "Fold River Overbet"
‚Ä¢ TL;DR: "Standard play until river where hero correctly folds to overbet"
‚Ä¢ Hand Score: 77/100
‚Ä¢ Mistakes Found: 1
‚Ä¢ Street Comments: 4/4

Street Comments:
    FLOP: "Standard <mix> with pocket pair on <board_texture>"
    TURN: "Check behind is optimal given <range villain> strength"
    RIVER: "Clear fold against overbet with <blockers> considerations"

Mistakes Identified:
    TURN: Betting would be better here (EV Loss: 0.8BB, Severity: 25/100)

Performance Report:
‚Ä¢ Total Execution Time   : 4237ms
    Hand Selection: 23ms (0.5%)
    Snapshot Generation: 15ms (0.4%)
    Solver Enrichment: 2814ms (66.4%)
    LLM Processing: 1389ms (32.8%)
‚Ä¢ Peak Memory Usage      : 187MB

Provider Usage:
    openai: 1 requests, 1143 tokens

‚úÖ LLM Flow Test Completed Successfully!
```

## Environment Setup

Make sure you have the required environment variables:

```bash
# Required for LLM analysis
OPENAI_API_KEY=your_openai_key_here

# Optional for other providers
GROK_API_KEY=your_grok_key_here
GOOGLE_API_KEY=your_google_key_here

# Database connection
MONGODB_URI=your_mongodb_connection_string
```

## Test Components

### Main Test Script
- `scripts/test-llm-flow.js` - Main test orchestrator

### Helper Modules
- `scripts/helpers/hand-selector.js` - Random hand selection utilities
- `scripts/helpers/benchmark.js` - High-precision timing measurements
- `scripts/helpers/display.js` - Pretty console output formatting

### Core Services Tested
- `utils/SolverLLMService.js` - Main LLM analysis service
- `utils/SolverBlockTrimmer.js` - Token optimization
- `utils/LLMPromptBuilder.js` - Prompt construction with UI tags
- `db/collections/Solves.js` - Solver data enrichment

## Troubleshooting

### Common Issues

**No hands found:**
```
‚ö†Ô∏è No suitable river hands found. Trying broader search...
```
- Check that your database has hands with `info.sawRiver: true`
- Verify MongoDB connection

**LLM API errors:**
```
‚ùå Test Failed: LLM analysis failed: API key not found
```
- Ensure `OPENAI_API_KEY` is set in your environment
- Check API key validity and rate limits

**Solver enrichment failures:**
```
Error in enhanced hand analysis: Vector search failed
```
- Verify vector database connectivity
- Check that solver data exists for the selected hand

### Performance Notes

- Solver enrichment typically takes 2-4 seconds per hand
- LLM processing usually takes 1-2 seconds
- Total test time is typically 4-6 seconds
- Memory usage peaks around 150-200MB

### Customization

You can modify the test behavior by editing the test script:

```javascript
// Use a specific hand ID instead of random
const hand = await findHandById(123456);

// Test different LLM providers
const llmService = new SolverLLMService({
    defaultModel: 'grok',  // or 'google'
    temperature: 0.5
});

// Test different scenarios
const hand = await findHandForScenario('complex');  // or 'simple', 'tournament'
```